{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount(x, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Action take at timestep t can affect all rewards in future.\n",
    "    Nearby rewards are most likely to be caused by actions, so we do a exponential decay.\n",
    "    \n",
    "    Given vector x, computes a vector y such that\n",
    "    y[i] = x[i] + gamma * x[i+1] + gamma^2 x[i+2] + ...\n",
    "    \"\"\"\n",
    "    out = np.zeros(len(x), 'float64')\n",
    "    out[-1] = x[-1]\n",
    "    for i in reversed(xrange(len(x)-1)):\n",
    "        out[i] = x[i] + gamma*out[i+1]\n",
    "    assert x.ndim >= 1\n",
    "    # More efficient version:\n",
    "    # scipy.signal.lfilter([1],[1,-gamma],x[::-1], axis=0)[::-1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_sample(prob_n):\n",
    "    \"\"\"\n",
    "    Weighted random sample given a discrete probability distribution\n",
    "    \"\"\"\n",
    "    prob_n = np.asarray(prob_n)\n",
    "    csprob_n = np.cumsum(prob_n)\n",
    "    r = np.random.rand()\n",
    "    return (csprob_n > r).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_advantages(list_of_rewards, discount_gamma):\n",
    "    discouted_rewards = []\n",
    "    for rewards in list_of_rewards:\n",
    "        discouted_rewards.append(discount(rewards, gamma=discount_gamma))\n",
    "    \n",
    "    maxlen = max(len(rew) for rew in list_of_rewards)\n",
    "    padded_rews = [np.concatenate([rew, np.zeros(maxlen-len(rew))]) for rew in discouted_rewards]\n",
    "    # Compute time-dependent baseline\n",
    "    baseline = np.mean(padded_rews, axis=0)\n",
    "    # Compute advantage function\n",
    "    advs = [rew - baseline[:len(rew)] for rew in discouted_rewards]\n",
    "    return np.concatenate(advs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = None\n",
    "\n",
    "def render_inline(image_array):\n",
    "    global img\n",
    "    if img is None:\n",
    "        img = plt.imshow(image_array)\n",
    "    else:\n",
    "        img.set_data(image_array)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(agent, env, episode_max_length, render=False):\n",
    "    \"\"\"\n",
    "    Run episode of environment and return results.\n",
    "    \"\"\"\n",
    "    global img\n",
    "    img = None\n",
    "    ob = env.reset()\n",
    "    obs = []\n",
    "    acts = []\n",
    "    rews = []\n",
    "    actual_rews = []\n",
    "    for _ in xrange(episode_max_length):\n",
    "        a = agent.act(ob)\n",
    "        (ob, rew, done, _) = env.step(a)\n",
    "        \n",
    "        obs.append(ob)\n",
    "        acts.append(a)\n",
    "        rews.append(rew)\n",
    "        actual_rews.append(rew) \n",
    "        if done: break\n",
    "        if render:\n",
    "            x = env.render(mode='rgb_array')\n",
    "            render_inline(x)\n",
    "            \n",
    "    # let's hack and say reward for each action is the maximum height achieved in future states\n",
    "    height_rewards = [obs[-1][0]]\n",
    "    max_so_far_height = obs[-1][0]\n",
    "    for i in xrange(len(actual_rews) - 2, -1, -1):\n",
    "        max_so_far_height = max(max_so_far_height, obs[i][0])\n",
    "        height_rewards.append(max_so_far_height)\n",
    "    height_rewards = np.array(list(reversed(height_rewards)))\n",
    "    \n",
    "    velocity_rewards = [abs(obs[-1][1])]\n",
    "    max_so_far_velocity = abs(obs[-1][1])\n",
    "    for i in xrange(len(actual_rews) - 2, -1, -1):\n",
    "        max_so_far_velocity = max(max_so_far_velocity, abs(obs[i][1]))\n",
    "        velocity_rewards.append(max_so_far_velocity)\n",
    "    velocity_rewards = np.array(list(reversed(velocity_rewards)))\n",
    "                         \n",
    "    hacked_rewards = height_rewards * 0.5 + velocity_rewards * 0.5\n",
    "    \n",
    "    return {\n",
    "        \"reward\" : hacked_rewards,\n",
    "        \"ob\" : np.array(obs),\n",
    "        \"action\" : np.array(acts),\n",
    "        \"actual_reward\": np.array(actual_rews),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naygHvJlZQ/0/AJTGoOWj0PwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f3ba050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DummyAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        \n",
    "    def act(self, _ob):\n",
    "        return env.action_space.sample()\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "x = run_episode(DummyAgent(env), env, env.spec.max_episode_steps, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.87554656e-01,   1.48767956e-03],\n",
       "       [ -5.85590245e-01,   1.96441105e-03],\n",
       "       [ -5.83163573e-01,   2.42667162e-03],\n",
       "       [ -5.81292539e-01,   1.87103389e-03],\n",
       "       [ -5.79990960e-01,   1.30157992e-03],\n",
       "       [ -5.79268453e-01,   7.22506709e-04],\n",
       "       [ -5.77130362e-01,   2.13809107e-03],\n",
       "       [ -5.73592507e-01,   3.53785442e-03],\n",
       "       [ -5.68681104e-01,   4.91140327e-03],\n",
       "       [ -5.64432613e-01,   4.24849088e-03],\n",
       "       [ -5.60878634e-01,   3.55397926e-03],\n",
       "       [ -5.58045638e-01,   2.83299569e-03],\n",
       "       [ -5.53954751e-01,   4.09088757e-03],\n",
       "       [ -5.49636508e-01,   4.31824282e-03],\n",
       "       [ -5.46123181e-01,   3.51332728e-03],\n",
       "       [ -5.42441049e-01,   3.68213179e-03],\n",
       "       [ -5.37617675e-01,   4.82337359e-03],\n",
       "       [ -5.33689191e-01,   3.92848434e-03],\n",
       "       [ -5.28685040e-01,   5.00415090e-03],\n",
       "       [ -5.23642744e-01,   5.04229640e-03],\n",
       "       [ -5.17600117e-01,   6.04262616e-03],\n",
       "       [ -5.10602479e-01,   6.99763865e-03],\n",
       "       [ -5.04702288e-01,   5.90019112e-03],\n",
       "       [ -4.98943744e-01,   5.75854336e-03],\n",
       "       [ -4.94369945e-01,   4.57379918e-03],\n",
       "       [ -4.89015081e-01,   5.35486377e-03],\n",
       "       [ -4.82919130e-01,   6.09595114e-03],\n",
       "       [ -4.77127520e-01,   5.79161057e-03],\n",
       "       [ -4.70683315e-01,   6.44420408e-03],\n",
       "       [ -4.65634313e-01,   5.04900290e-03],\n",
       "       [ -4.61017856e-01,   4.61645709e-03],\n",
       "       [ -4.55868003e-01,   5.14985260e-03],\n",
       "       [ -4.52222643e-01,   3.64536011e-03],\n",
       "       [ -4.50108522e-01,   2.11412057e-03],\n",
       "       [ -4.48541124e-01,   1.56739804e-03],\n",
       "       [ -4.46531914e-01,   2.00921066e-03],\n",
       "       [ -4.46095569e-01,   4.36344834e-04],\n",
       "       [ -4.46235275e-01,  -1.39706007e-04],\n",
       "       [ -4.47950012e-01,  -1.71473720e-03],\n",
       "       [ -4.49227257e-01,  -1.27724513e-03],\n",
       "       [ -4.52057672e-01,  -2.83041524e-03],\n",
       "       [ -4.54420536e-01,  -2.36286373e-03],\n",
       "       [ -4.58298520e-01,  -3.87798410e-03],\n",
       "       [ -4.61663130e-01,  -3.36460948e-03],\n",
       "       [ -4.66489588e-01,  -4.82645858e-03],\n",
       "       [ -4.72742273e-01,  -6.25268515e-03],\n",
       "       [ -4.79374904e-01,  -6.63263087e-03],\n",
       "       [ -4.85338242e-01,  -5.96333774e-03],\n",
       "       [ -4.92587904e-01,  -7.24966207e-03],\n",
       "       [ -5.00069812e-01,  -7.48190825e-03],\n",
       "       [ -5.08728041e-01,  -8.65822897e-03],\n",
       "       [ -5.17497764e-01,  -8.76972248e-03],\n",
       "       [ -5.27313241e-01,  -9.81547752e-03],\n",
       "       [ -5.37100861e-01,  -9.78761960e-03],\n",
       "       [ -5.45787242e-01,  -8.68638165e-03],\n",
       "       [ -5.55307333e-01,  -9.52009102e-03],\n",
       "       [ -5.63589969e-01,  -8.28263533e-03],\n",
       "       [ -5.70573389e-01,  -6.98342039e-03],\n",
       "       [ -5.77205665e-01,  -6.63227575e-03],\n",
       "       [ -5.82437620e-01,  -5.23195490e-03],\n",
       "       [ -5.87230571e-01,  -4.79295163e-03],\n",
       "       [ -5.91549178e-01,  -4.31860640e-03],\n",
       "       [ -5.95361679e-01,  -3.81250068e-03],\n",
       "       [ -5.98640106e-01,  -3.27842698e-03],\n",
       "       [ -6.01360464e-01,  -2.72035892e-03],\n",
       "       [ -6.04502886e-01,  -3.14242180e-03],\n",
       "       [ -6.08044467e-01,  -3.54158095e-03],\n",
       "       [ -6.09959458e-01,  -1.91499118e-03],\n",
       "       [ -6.12233966e-01,  -2.27450782e-03],\n",
       "       [ -6.13851516e-01,  -1.61755001e-03],\n",
       "       [ -6.14800411e-01,  -9.48894733e-04],\n",
       "       [ -6.16073796e-01,  -1.27338473e-03],\n",
       "       [ -6.15662480e-01,   4.11315454e-04],\n",
       "       [ -6.13569432e-01,   2.09304821e-03],\n",
       "       [ -6.11809767e-01,   1.75966469e-03],\n",
       "       [ -6.09396215e-01,   2.41355229e-03],\n",
       "       [ -6.06346264e-01,   3.04995140e-03],\n",
       "       [ -6.01682061e-01,   4.66420310e-03],\n",
       "       [ -5.97437574e-01,   4.24448658e-03],\n",
       "       [ -5.92643814e-01,   4.79375962e-03],\n",
       "       [ -5.86335912e-01,   6.30790238e-03],\n",
       "       [ -5.78560254e-01,   7.77565786e-03],\n",
       "       [ -5.71374250e-01,   7.18600369e-03],\n",
       "       [ -5.62831156e-01,   8.54309423e-03],\n",
       "       [ -5.53994498e-01,   8.83665822e-03],\n",
       "       [ -5.43930188e-01,   1.00643103e-02],\n",
       "       [ -5.32713486e-01,   1.12167014e-02],\n",
       "       [ -5.20428433e-01,   1.22850532e-02],\n",
       "       [ -5.09167157e-01,   1.12612760e-02],\n",
       "       [ -4.98014084e-01,   1.11530727e-02],\n",
       "       [ -4.86052709e-01,   1.19613758e-02],\n",
       "       [ -4.75372333e-01,   1.06803754e-02],\n",
       "       [ -4.64052396e-01,   1.13199376e-02],\n",
       "       [ -4.53176684e-01,   1.08757113e-02],\n",
       "       [ -4.41825218e-01,   1.13514658e-02],\n",
       "       [ -4.32080921e-01,   9.74429729e-03],\n",
       "       [ -4.22014417e-01,   1.00665042e-02],\n",
       "       [ -4.11698057e-01,   1.03163601e-02],\n",
       "       [ -4.01205277e-01,   1.04927795e-02],\n",
       "       [ -3.92609961e-01,   8.59531630e-03],\n",
       "       [ -3.83971971e-01,   8.63799023e-03],\n",
       "       [ -3.75350825e-01,   8.62114544e-03],\n",
       "       [ -3.68805247e-01,   6.54557878e-03],\n",
       "       [ -3.64379340e-01,   4.42590610e-03],\n",
       "       [ -3.61102686e-01,   3.27665400e-03],\n",
       "       [ -3.59997053e-01,   1.10563345e-03],\n",
       "       [ -3.59069760e-01,   9.27293047e-04],\n",
       "       [ -3.58326936e-01,   7.42823489e-04],\n",
       "       [ -3.59773486e-01,  -1.44654932e-03],\n",
       "       [ -3.62399854e-01,  -2.62636828e-03],\n",
       "       [ -3.67188639e-01,  -4.78878451e-03],\n",
       "       [ -3.73107923e-01,  -5.91928454e-03],\n",
       "       [ -3.81117935e-01,  -8.01001209e-03],\n",
       "       [ -3.90164309e-01,  -9.04637404e-03],\n",
       "       [ -4.00184928e-01,  -1.00206185e-02],\n",
       "       [ -4.10110148e-01,  -9.92522002e-03],\n",
       "       [ -4.20870183e-01,  -1.07600357e-02],\n",
       "       [ -4.31388545e-01,  -1.05183617e-02],\n",
       "       [ -4.43589697e-01,  -1.22011517e-02],\n",
       "       [ -4.57385171e-01,  -1.37954744e-02],\n",
       "       [ -4.72673988e-01,  -1.52888170e-02],\n",
       "       [ -4.89343257e-01,  -1.66692689e-02],\n",
       "       [ -5.07268990e-01,  -1.79257333e-02],\n",
       "       [ -5.24317148e-01,  -1.70481577e-02],\n",
       "       [ -5.42359918e-01,  -1.80427699e-02],\n",
       "       [ -5.60262054e-01,  -1.79021356e-02],\n",
       "       [ -5.76889769e-01,  -1.66277152e-02],\n",
       "       [ -5.93119502e-01,  -1.62297331e-02],\n",
       "       [ -6.07831601e-01,  -1.47120995e-02],\n",
       "       [ -6.21918657e-01,  -1.40870554e-02],\n",
       "       [ -6.34278959e-01,  -1.23603023e-02],\n",
       "       [ -6.46824329e-01,  -1.25453703e-02],\n",
       "       [ -6.57466415e-01,  -1.06420854e-02],\n",
       "       [ -6.66131265e-01,  -8.66484985e-03],\n",
       "       [ -6.73759400e-01,  -7.62813539e-03],\n",
       "       [ -6.79299037e-01,  -5.53963693e-03],\n",
       "       [ -6.82712925e-01,  -3.41388809e-03],\n",
       "       [ -6.85978262e-01,  -3.26533731e-03],\n",
       "       [ -6.88073352e-01,  -2.09508947e-03],\n",
       "       [ -6.87984331e-01,   8.90205115e-05],\n",
       "       [ -6.86711789e-01,   1.27254244e-03],\n",
       "       [ -6.83264140e-01,   3.44764893e-03],\n",
       "       [ -6.77664270e-01,   5.59987014e-03],\n",
       "       [ -6.70949612e-01,   6.71465814e-03],\n",
       "       [ -6.64165465e-01,   6.78414708e-03],\n",
       "       [ -6.55358037e-01,   8.80742752e-03],\n",
       "       [ -6.44587948e-01,   1.07700889e-02],\n",
       "       [ -6.31930234e-01,   1.26577139e-02],\n",
       "       [ -6.18474262e-01,   1.34559725e-02],\n",
       "       [ -6.05316292e-01,   1.31579699e-02],\n",
       "       [ -5.90551561e-01,   1.47647307e-02],\n",
       "       [ -5.74288054e-01,   1.62635070e-02],\n",
       "       [ -5.56645841e-01,   1.76422130e-02],\n",
       "       [ -5.38756181e-01,   1.78896602e-02],\n",
       "       [ -5.20752880e-01,   1.80033016e-02],\n",
       "       [ -5.02770922e-01,   1.79819576e-02],\n",
       "       [ -4.84945072e-01,   1.78258503e-02],\n",
       "       [ -4.68408475e-01,   1.65365968e-02],\n",
       "       [ -4.52283917e-01,   1.61245582e-02],\n",
       "       [ -4.36690149e-01,   1.55937677e-02],\n",
       "       [ -4.20740836e-01,   1.59493128e-02],\n",
       "       [ -4.05550774e-01,   1.51900625e-02],\n",
       "       [ -3.92227680e-01,   1.33230934e-02],\n",
       "       [ -3.80864561e-01,   1.13631194e-02],\n",
       "       [ -3.69539532e-01,   1.13250284e-02],\n",
       "       [ -3.60329250e-01,   9.21028242e-03],\n",
       "       [ -3.52295110e-01,   8.03413996e-03],\n",
       "       [ -3.45489937e-01,   6.80517295e-03],\n",
       "       [ -3.40957918e-01,   4.53201908e-03],\n",
       "       [ -3.38728186e-01,   2.22973147e-03],\n",
       "       [ -3.37814988e-01,   9.13198215e-04],\n",
       "       [ -3.37224141e-01,   5.90847552e-04],\n",
       "       [ -3.37959402e-01,  -7.35261744e-04],\n",
       "       [ -3.39016095e-01,  -1.05669310e-03],\n",
       "       [ -3.40387486e-01,  -1.37139021e-03],\n",
       "       [ -3.44064814e-01,  -3.67732786e-03],\n",
       "       [ -3.48024482e-01,  -3.95966865e-03],\n",
       "       [ -3.53240909e-01,  -5.21642642e-03],\n",
       "       [ -3.59680120e-01,  -6.43921128e-03],\n",
       "       [ -3.68299767e-01,  -8.61964756e-03],\n",
       "       [ -3.77042476e-01,  -8.74270856e-03],\n",
       "       [ -3.86849284e-01,  -9.80680825e-03],\n",
       "       [ -3.96653185e-01,  -9.80390124e-03],\n",
       "       [ -4.07386330e-01,  -1.07331448e-02],\n",
       "       [ -4.18973519e-01,  -1.15871884e-02],\n",
       "       [ -4.31332575e-01,  -1.23590568e-02],\n",
       "       [ -4.44374826e-01,  -1.30422506e-02],\n",
       "       [ -4.59005678e-01,  -1.46308520e-02],\n",
       "       [ -4.75117952e-01,  -1.61122740e-02],\n",
       "       [ -4.90592552e-01,  -1.54745996e-02],\n",
       "       [ -5.05314294e-01,  -1.47217420e-02],\n",
       "       [ -5.21173101e-01,  -1.58588069e-02],\n",
       "       [ -5.37050100e-01,  -1.58769993e-02],\n",
       "       [ -5.51826242e-01,  -1.47761417e-02],\n",
       "       [ -5.65390930e-01,  -1.35646886e-02],\n",
       "       [ -5.79642998e-01,  -1.42520680e-02],\n",
       "       [ -5.92476712e-01,  -1.28337139e-02],\n",
       "       [ -6.05797510e-01,  -1.33207977e-02],\n",
       "       [ -6.18508046e-01,  -1.27105363e-02],\n",
       "       [ -6.29516342e-01,  -1.10082957e-02]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"ob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15959069, -0.15959069, -0.15959069, -0.15959069, -0.15959069,\n",
       "       -0.15961042, -0.15961042, -0.15961042, -0.15961042, -0.15961042,\n",
       "       -0.15961042, -0.15961042, -0.15961042, -0.15961042, -0.15961042,\n",
       "       -0.15961042, -0.15961042, -0.15961042, -0.15961042, -0.15961042,\n",
       "       -0.15961042, -0.15961042, -0.15961042, -0.15961042, -0.15961042,\n",
       "       -0.15961042, -0.15961042, -0.15961042, -0.15961042, -0.15961042,\n",
       "       -0.15961042, -0.15961042, -0.15961042, -0.15961042, -0.15961042,\n",
       "       -0.15962109, -0.15969915, -0.16034377, -0.16054979, -0.16055593,\n",
       "       -0.16055593, -0.16055593, -0.16055593, -0.16055593, -0.16055593,\n",
       "       -0.16055593, -0.16055593, -0.16055593, -0.16055593, -0.16055593,\n",
       "       -0.16055593, -0.16055593, -0.16092356, -0.16145191, -0.16213761,\n",
       "       -0.16397627, -0.1659561 , -0.16856432, -0.17178392, -0.17609375,\n",
       "       -0.1804651 , -0.18536851, -0.19027046, -0.19563703, -0.20143062,\n",
       "       -0.20761015, -0.21413128, -0.2214467 , -0.22950284, -0.23735778,\n",
       "       -0.24471865, -0.25264805, -0.26058655, -0.26852505, -0.27556943,\n",
       "       -0.28269547, -0.28957796, -0.29623836, -0.30289875, -0.30925402])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"reward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"actual_reward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_variables(env, num_hidden):\n",
    "    W0 = tf.get_variable(\n",
    "        \"W0\",\n",
    "        [env.observation_space.shape[0], num_hidden],\n",
    "        initializer = tf.contrib.layers.xavier_initializer(),\n",
    "    )\n",
    "    b0 = tf.get_variable(\n",
    "        \"b0\",\n",
    "        [num_hidden]\n",
    "    )\n",
    "    W1 = tf.get_variable(\n",
    "        \"W1\", \n",
    "        [num_hidden, env.action_space.n],\n",
    "        initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    )\n",
    "    b1 = tf.get_variable(\"b1\", [env.action_space.n])\n",
    "    return [W0, b0, W1, b1]\n",
    "    \n",
    "\n",
    "class PolicyGradientAgent:\n",
    "    def __init__(self, env, learning_rate=0.001, num_hidden=8):\n",
    "        self.X = tf.placeholder(dtype=tf.float32, shape=[None, env.observation_space.shape[0]], name=\"X\")\n",
    "        \n",
    "        self.Adv = tf.placeholder(dtype=tf.float32, shape=[None, 1], name=\"Adv\")\n",
    "        self.Actions = tf.placeholder(dtype=tf.int32, shape=[None, 2], name=\"Actions\")\n",
    "        \n",
    "        self.W0, self.b0, self.W1, self.b1 = declare_variables(env, num_hidden)\n",
    "        \n",
    "        self.hidden = tf.nn.relu(tf.add(tf.matmul(self.X, self.W0), self.b0))\n",
    "        self.probs = tf.nn.softmax(tf.add(tf.matmul(self.hidden, self.W1), self.b1))\n",
    "        \n",
    "        action_probs = tf.expand_dims(tf.gather_nd(self.probs, self.Actions), 1)\n",
    "        policy_advantage = tf.reduce_mean(tf.multiply(tf.log(action_probs), self.Adv))\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(-policy_advantage)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        self.params = None\n",
    "        \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "        \n",
    "    def _numpy_softmax(self, X):\n",
    "        W0, b0, W1, b1 = self.params\n",
    "        hidden = np.dot(X, W0) + b0\n",
    "        hidden[hidden < 0.] = 0.\n",
    "        output_pre = np.dot(hidden, W1) + b1\n",
    "        softmax = np.exp(output_pre)\n",
    "        softmax /= softmax.sum()\n",
    "        return softmax\n",
    "        \n",
    "    def save(self, sess, filename):\n",
    "        return self.saver.save(sess, filename)\n",
    "        \n",
    "    def restore(self, sess, filename):\n",
    "        self.saver.restore(sess, filename)\n",
    "        \n",
    "    def act(self, ob):\n",
    "        action_probs = self._numpy_softmax(np.array([ob]))\n",
    "        action = categorical_sample(action_probs[0])\n",
    "        return action\n",
    "    \n",
    "    def learn(self, sess, all_obs, all_actions, all_advantages):\n",
    "        result = sess.run(\n",
    "            self.optimizer,\n",
    "            feed_dict={\n",
    "                self.X: all_obs,\n",
    "                self.Actions: np.hstack([np.arange(all_actions.shape[0])[:, None], all_actions[:, None]]),\n",
    "                self.Adv: all_advantages[:, None],\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrKb+H/MK5iEFqjoXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11813ef10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    agent = PolicyGradientAgent(env)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    params = sess.run([agent.W0, agent.b0, agent.W1, agent.b1])\n",
    "    agent.set_params(params)\n",
    "    \n",
    "    x = run_episode(agent, env, env.spec.max_episode_steps, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.489383\n",
      "Maximum weighted reward -0.170769, Average weighted reward: -0.220349, Std dev weighted reward: 0.021546\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.356095, Average height: -0.513365, Std dev height: 0.047830\n",
      "Maximum velocity 0.014558, Average velocity: 0.003308, Std dev velocity: 0.002516\n",
      "0.489383\n"
     ]
    }
   ],
   "source": [
    "def run_single_iteration(sess, batch_size, discount_gamma, print_summary=False):\n",
    "    results = []\n",
    "    for _ in xrange(batch_size):\n",
    "        results.append(run_episode(agent, env, env.spec.max_episode_steps, render=False))\n",
    "        \n",
    "    all_obs = np.concatenate([x[\"ob\"] for x in results])\n",
    "    all_actions = np.concatenate([x[\"action\"] for x in results])\n",
    "    all_advs = calculate_advantages([x[\"reward\"] for x in results], discount_gamma)\n",
    "    \n",
    "    agent.learn(sess, all_obs, all_actions, all_advs)\n",
    "    agent.set_params(sess.run([agent.W0, agent.b0, agent.W1, agent.b1]))\n",
    "    \n",
    "    if print_summary:\n",
    "        print(\"Maximum weighted reward %f, Average weighted reward: %f, Std dev weighted reward: %f\" % (\n",
    "                max(x[\"reward\"].max() for x in results),\n",
    "                np.concatenate([x[\"reward\"] for x in results]).mean(),\n",
    "                np.concatenate([x[\"reward\"] for x in results]).std(),\n",
    "            )\n",
    "        )\n",
    "        print(\"Maximum episode length %d, Average episode length: %f, Std dev episode length: %f\" % (\n",
    "                max(len(x[\"reward\"]) for x in results),\n",
    "                np.array([len(x[\"reward\"]) for x in results]).mean(),\n",
    "                np.array([len(x[\"reward\"]) for x in results]).std(),\n",
    "            )\n",
    "        )\n",
    "        print(\"Maximum actual reward %d, Average actual rewards: %f, Std dev actual rewards: %f\" % (\n",
    "                max(x[\"actual_reward\"].sum() for x in results),\n",
    "                np.array([x[\"actual_reward\"].sum() for x in results]).mean(),\n",
    "                np.array([x[\"actual_reward\"].sum() for x in results]).std(),\n",
    "            )\n",
    "        )\n",
    "        print(\"Maximum height %f, Average height: %f, Std dev height: %f\" % (\n",
    "                max(x[\"ob\"][:, 0].max() for x in results),\n",
    "                np.concatenate([x[\"ob\"][:, 0] for x in results]).mean(),\n",
    "                np.concatenate([x[\"ob\"][:, 0] for x in results]).std(),\n",
    "            )\n",
    "        )\n",
    "        print(\"Maximum velocity %f, Average velocity: %f, Std dev velocity: %f\" % (\n",
    "                max(np.abs(x[\"ob\"][:, 1]).max() for x in results),\n",
    "                np.concatenate([np.abs(x[\"ob\"][:, 1]) for x in results]).mean(),\n",
    "                np.concatenate([np.abs(x[\"ob\"][:, 1]) for x in results]).std(),\n",
    "            )\n",
    "        )\n",
    "    return np.concatenate([x[\"reward\"] for x in results]).mean()\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    agent = PolicyGradientAgent(env, learning_rate=0.001)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    agent.set_params(sess.run([agent.W0, agent.b0, agent.W1, agent.b1]))\n",
    "    \n",
    "    print(agent.params[0][0][0])\n",
    "    run_single_iteration(sess, batch_size=50, discount_gamma=0.9, print_summary=True)\n",
    "    print(agent.params[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Iteration 100--------------------------\n",
      "Maximum weighted reward -0.078924, Average weighted reward: -0.176928, Std dev weighted reward: 0.039858\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.181522, Average height: -0.478818, Std dev height: 0.078919\n",
      "Maximum velocity 0.024690, Average velocity: 0.005188, Std dev velocity: 0.004184\n",
      "-----------------------------------------------------\n",
      "-0.255032\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 200--------------------------\n",
      "Maximum weighted reward -0.062045, Average weighted reward: -0.127904, Std dev weighted reward: 0.037335\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.142741, Average height: -0.377773, Std dev height: 0.096045\n",
      "Maximum velocity 0.019633, Average velocity: 0.006010, Std dev velocity: 0.004736\n",
      "-----------------------------------------------------\n",
      "-0.32307\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 300--------------------------\n",
      "Maximum weighted reward 0.029689, Average weighted reward: -0.121087, Std dev weighted reward: 0.047514\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.026063, Average height: -0.398654, Std dev height: 0.103510\n",
      "Maximum velocity 0.033315, Average velocity: 0.006379, Std dev velocity: 0.005108\n",
      "-----------------------------------------------------\n",
      "-0.409976\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 400--------------------------\n",
      "Maximum weighted reward 0.276455, Average weighted reward: -0.079719, Std dev weighted reward: 0.107718\n",
      "Maximum episode length 200, Average episode length: 199.990000, Std dev episode length: 0.099499\n",
      "Maximum actual reward -199, Average actual rewards: -199.990000, Std dev actual rewards: 0.099499\n",
      "Maximum height 0.508197, Average height: -0.567130, Std dev height: 0.207820\n",
      "Maximum velocity 0.044712, Average velocity: 0.009614, Std dev velocity: 0.008042\n",
      "-----------------------------------------------------\n",
      "-0.637292\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 500--------------------------\n",
      "Maximum weighted reward 0.287352, Average weighted reward: 0.061453, Std dev weighted reward: 0.150401\n",
      "Maximum episode length 200, Average episode length: 199.720000, Std dev episode length: 1.442775\n",
      "Maximum actual reward -191, Average actual rewards: -199.720000, Std dev actual rewards: 1.442775\n",
      "Maximum height 0.526898, Average height: -0.559792, Std dev height: 0.301165\n",
      "Maximum velocity 0.049440, Average velocity: 0.013543, Std dev velocity: 0.010913\n",
      "-----------------------------------------------------\n",
      "-0.626005\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 600--------------------------\n",
      "Maximum weighted reward 0.286742, Average weighted reward: 0.109697, Std dev weighted reward: 0.148094\n",
      "Maximum episode length 200, Average episode length: 198.850000, Std dev episode length: 2.957617\n",
      "Maximum actual reward -181, Average actual rewards: -198.850000, Std dev actual rewards: 2.957617\n",
      "Maximum height 0.523294, Average height: -0.550360, Std dev height: 0.332450\n",
      "Maximum velocity 0.053926, Average velocity: 0.015654, Std dev velocity: 0.012582\n",
      "-----------------------------------------------------\n",
      "-0.648589\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 700--------------------------\n",
      "Maximum weighted reward 0.289718, Average weighted reward: 0.127804, Std dev weighted reward: 0.156507\n",
      "Maximum episode length 200, Average episode length: 197.960000, Std dev episode length: 6.046354\n",
      "Maximum actual reward -156, Average actual rewards: -197.960000, Std dev actual rewards: 6.046354\n",
      "Maximum height 0.530008, Average height: -0.542780, Std dev height: 0.342518\n",
      "Maximum velocity 0.055845, Average velocity: 0.016008, Std dev velocity: 0.013027\n",
      "-----------------------------------------------------\n",
      "-0.656958\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 800--------------------------\n",
      "Maximum weighted reward 0.291396, Average weighted reward: 0.019939, Std dev weighted reward: 0.172835\n",
      "Maximum episode length 200, Average episode length: 199.900000, Std dev episode length: 0.670820\n",
      "Maximum actual reward -194, Average actual rewards: -199.900000, Std dev actual rewards: 0.670820\n",
      "Maximum height 0.532371, Average height: -0.582211, Std dev height: 0.286299\n",
      "Maximum velocity 0.050421, Average velocity: 0.012984, Std dev velocity: 0.010461\n",
      "-----------------------------------------------------\n",
      "-0.656946\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 900--------------------------\n",
      "Maximum weighted reward 0.290992, Average weighted reward: 0.136439, Std dev weighted reward: 0.160820\n",
      "Maximum episode length 200, Average episode length: 199.280000, Std dev episode length: 2.097999\n",
      "Maximum actual reward -187, Average actual rewards: -199.280000, Std dev actual rewards: 2.097999\n",
      "Maximum height 0.530974, Average height: -0.555110, Std dev height: 0.337500\n",
      "Maximum velocity 0.052566, Average velocity: 0.015488, Std dev velocity: 0.012640\n",
      "-----------------------------------------------------\n",
      "-0.641854\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1000--------------------------\n",
      "Maximum weighted reward 0.289010, Average weighted reward: 0.136973, Std dev weighted reward: 0.157330\n",
      "Maximum episode length 200, Average episode length: 198.030000, Std dev episode length: 3.522655\n",
      "Maximum actual reward -185, Average actual rewards: -198.030000, Std dev actual rewards: 3.522655\n",
      "Maximum height 0.526576, Average height: -0.550867, Std dev height: 0.340201\n",
      "Maximum velocity 0.052536, Average velocity: 0.015699, Std dev velocity: 0.012731\n",
      "-----------------------------------------------------\n",
      "-0.581198\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1100--------------------------\n",
      "Maximum weighted reward 0.288929, Average weighted reward: 0.069974, Std dev weighted reward: 0.160851\n",
      "Maximum episode length 200, Average episode length: 199.660000, Std dev episode length: 1.595118\n",
      "Maximum actual reward -189, Average actual rewards: -199.660000, Std dev actual rewards: 1.595118\n",
      "Maximum height 0.529932, Average height: -0.567575, Std dev height: 0.312277\n",
      "Maximum velocity 0.052414, Average velocity: 0.014222, Std dev velocity: 0.010728\n",
      "-----------------------------------------------------\n",
      "-0.630562\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1200--------------------------\n",
      "Maximum weighted reward 0.293446, Average weighted reward: 0.118748, Std dev weighted reward: 0.153789\n",
      "Maximum episode length 200, Average episode length: 199.090000, Std dev episode length: 2.421136\n",
      "Maximum actual reward -186, Average actual rewards: -199.090000, Std dev actual rewards: 2.421136\n",
      "Maximum height 0.534991, Average height: -0.551034, Std dev height: 0.335476\n",
      "Maximum velocity 0.051902, Average velocity: 0.015412, Std dev velocity: 0.011946\n",
      "-----------------------------------------------------\n",
      "-0.639125\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1300--------------------------\n",
      "Maximum weighted reward 0.293409, Average weighted reward: 0.112210, Std dev weighted reward: 0.141909\n",
      "Maximum episode length 200, Average episode length: 199.230000, Std dev episode length: 2.595592\n",
      "Maximum actual reward -182, Average actual rewards: -199.230000, Std dev actual rewards: 2.595592\n",
      "Maximum height 0.534973, Average height: -0.545471, Std dev height: 0.329665\n",
      "Maximum velocity 0.055481, Average velocity: 0.015196, Std dev velocity: 0.012020\n",
      "-----------------------------------------------------\n",
      "-0.644879\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1400--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum weighted reward 0.291564, Average weighted reward: 0.050090, Std dev weighted reward: 0.166476\n",
      "Maximum episode length 200, Average episode length: 199.830000, Std dev episode length: 0.949263\n",
      "Maximum actual reward -191, Average actual rewards: -199.830000, Std dev actual rewards: 0.949263\n",
      "Maximum height 0.531801, Average height: -0.558983, Std dev height: 0.298300\n",
      "Maximum velocity 0.051328, Average velocity: 0.013554, Std dev velocity: 0.010933\n",
      "-----------------------------------------------------\n",
      "-0.613825\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1500--------------------------\n",
      "Maximum weighted reward 0.291834, Average weighted reward: 0.104663, Std dev weighted reward: 0.178982\n",
      "Maximum episode length 200, Average episode length: 198.570000, Std dev episode length: 3.244241\n",
      "Maximum actual reward -186, Average actual rewards: -198.570000, Std dev actual rewards: 3.244241\n",
      "Maximum height 0.532620, Average height: -0.544369, Std dev height: 0.328509\n",
      "Maximum velocity 0.056263, Average velocity: 0.014891, Std dev velocity: 0.012136\n",
      "-----------------------------------------------------\n",
      "-0.605456\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1600--------------------------\n",
      "Maximum weighted reward 0.292860, Average weighted reward: 0.070170, Std dev weighted reward: 0.188846\n",
      "Maximum episode length 200, Average episode length: 198.800000, Std dev episode length: 8.042388\n",
      "Maximum actual reward -120, Average actual rewards: -198.800000, Std dev actual rewards: 8.042388\n",
      "Maximum height 0.534624, Average height: -0.560193, Std dev height: 0.318876\n",
      "Maximum velocity 0.052841, Average velocity: 0.014248, Std dev velocity: 0.011393\n",
      "-----------------------------------------------------\n",
      "-0.607051\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1700--------------------------\n",
      "Maximum weighted reward 0.294246, Average weighted reward: 0.123347, Std dev weighted reward: 0.155082\n",
      "Maximum episode length 200, Average episode length: 199.360000, Std dev episode length: 1.774937\n",
      "Maximum actual reward -190, Average actual rewards: -199.360000, Std dev actual rewards: 1.774937\n",
      "Maximum height 0.535730, Average height: -0.541154, Std dev height: 0.337822\n",
      "Maximum velocity 0.054266, Average velocity: 0.015334, Std dev velocity: 0.011709\n",
      "-----------------------------------------------------\n",
      "-0.579333\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1800--------------------------\n",
      "Maximum weighted reward 0.298903, Average weighted reward: 0.125153, Std dev weighted reward: 0.157080\n",
      "Maximum episode length 200, Average episode length: 196.290000, Std dev episode length: 12.099004\n",
      "Maximum actual reward -110, Average actual rewards: -196.290000, Std dev actual rewards: 12.099004\n",
      "Maximum height 0.541658, Average height: -0.506049, Std dev height: 0.337658\n",
      "Maximum velocity 0.059023, Average velocity: 0.015180, Std dev velocity: 0.012631\n",
      "-----------------------------------------------------\n",
      "-0.546975\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 1900--------------------------\n",
      "Maximum weighted reward 0.295652, Average weighted reward: 0.154504, Std dev weighted reward: 0.147214\n",
      "Maximum episode length 200, Average episode length: 197.810000, Std dev episode length: 4.592810\n",
      "Maximum actual reward -178, Average actual rewards: -197.810000, Std dev actual rewards: 4.592810\n",
      "Maximum height 0.537772, Average height: -0.519637, Std dev height: 0.345436\n",
      "Maximum velocity 0.056804, Average velocity: 0.015792, Std dev velocity: 0.012934\n",
      "-----------------------------------------------------\n",
      "-0.560381\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2000--------------------------\n",
      "Maximum weighted reward 0.299368, Average weighted reward: 0.188492, Std dev weighted reward: 0.120091\n",
      "Maximum episode length 200, Average episode length: 195.820000, Std dev episode length: 12.539043\n",
      "Maximum actual reward -98, Average actual rewards: -195.820000, Std dev actual rewards: 12.539043\n",
      "Maximum height 0.541838, Average height: -0.523357, Std dev height: 0.361488\n",
      "Maximum velocity 0.057322, Average velocity: 0.016516, Std dev velocity: 0.012867\n",
      "-----------------------------------------------------\n",
      "-0.536062\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2100--------------------------\n",
      "Maximum weighted reward 0.294527, Average weighted reward: 0.150488, Std dev weighted reward: 0.141646\n",
      "Maximum episode length 200, Average episode length: 197.740000, Std dev episode length: 6.344478\n",
      "Maximum actual reward -151, Average actual rewards: -197.740000, Std dev actual rewards: 6.344478\n",
      "Maximum height 0.534460, Average height: -0.534474, Std dev height: 0.344035\n",
      "Maximum velocity 0.057382, Average velocity: 0.015317, Std dev velocity: 0.012062\n",
      "-----------------------------------------------------\n",
      "-0.530969\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2200--------------------------\n",
      "Maximum weighted reward 0.293342, Average weighted reward: 0.134823, Std dev weighted reward: 0.153153\n",
      "Maximum episode length 200, Average episode length: 198.830000, Std dev episode length: 3.124276\n",
      "Maximum actual reward -179, Average actual rewards: -198.830000, Std dev actual rewards: 3.124276\n",
      "Maximum height 0.532222, Average height: -0.531543, Std dev height: 0.353407\n",
      "Maximum velocity 0.054476, Average velocity: 0.016218, Std dev velocity: 0.012528\n",
      "-----------------------------------------------------\n",
      "-0.506497\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2300--------------------------\n",
      "Maximum weighted reward 0.291691, Average weighted reward: 0.103244, Std dev weighted reward: 0.151186\n",
      "Maximum episode length 200, Average episode length: 199.660000, Std dev episode length: 1.484722\n",
      "Maximum actual reward -189, Average actual rewards: -199.660000, Std dev actual rewards: 1.484722\n",
      "Maximum height 0.532947, Average height: -0.558829, Std dev height: 0.333139\n",
      "Maximum velocity 0.050957, Average velocity: 0.015241, Std dev velocity: 0.011729\n",
      "-----------------------------------------------------\n",
      "-0.520894\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2400--------------------------\n",
      "Maximum weighted reward 0.288202, Average weighted reward: 0.110258, Std dev weighted reward: 0.160954\n",
      "Maximum episode length 200, Average episode length: 198.900000, Std dev episode length: 2.692582\n",
      "Maximum actual reward -189, Average actual rewards: -198.900000, Std dev actual rewards: 2.692582\n",
      "Maximum height 0.527854, Average height: -0.558705, Std dev height: 0.340476\n",
      "Maximum velocity 0.049192, Average velocity: 0.015490, Std dev velocity: 0.011391\n",
      "-----------------------------------------------------\n",
      "-0.491984\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2500--------------------------\n",
      "Maximum weighted reward 0.277755, Average weighted reward: 0.094939, Std dev weighted reward: 0.146901\n",
      "Maximum episode length 200, Average episode length: 199.880000, Std dev episode length: 0.778203\n",
      "Maximum actual reward -194, Average actual rewards: -199.880000, Std dev actual rewards: 0.778203\n",
      "Maximum height 0.509943, Average height: -0.562233, Std dev height: 0.331219\n",
      "Maximum velocity 0.048765, Average velocity: 0.015050, Std dev velocity: 0.011407\n",
      "-----------------------------------------------------\n",
      "-0.482212\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2600--------------------------\n",
      "Maximum weighted reward 0.282396, Average weighted reward: 0.127733, Std dev weighted reward: 0.145626\n",
      "Maximum episode length 200, Average episode length: 198.360000, Std dev episode length: 5.094154\n",
      "Maximum actual reward -158, Average actual rewards: -198.360000, Std dev actual rewards: 5.094154\n",
      "Maximum height 0.520420, Average height: -0.531174, Std dev height: 0.352196\n",
      "Maximum velocity 0.050935, Average velocity: 0.015889, Std dev velocity: 0.012367\n",
      "-----------------------------------------------------\n",
      "-0.495822\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2700--------------------------\n",
      "Maximum weighted reward 0.285306, Average weighted reward: 0.097112, Std dev weighted reward: 0.141195\n",
      "Maximum episode length 200, Average episode length: 199.700000, Std dev episode length: 1.220656\n",
      "Maximum actual reward -192, Average actual rewards: -199.700000, Std dev actual rewards: 1.220656\n",
      "Maximum height 0.525190, Average height: -0.540760, Std dev height: 0.336674\n",
      "Maximum velocity 0.047034, Average velocity: 0.014898, Std dev velocity: 0.011781\n",
      "-----------------------------------------------------\n",
      "-0.393354\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Iteration 2800--------------------------\n",
      "Maximum weighted reward 0.272604, Average weighted reward: 0.066979, Std dev weighted reward: 0.144464\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.503903, Average height: -0.552160, Std dev height: 0.326802\n",
      "Maximum velocity 0.048208, Average velocity: 0.014818, Std dev velocity: 0.011159\n",
      "-----------------------------------------------------\n",
      "-0.331332\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 2900--------------------------\n",
      "Maximum weighted reward 0.286000, Average weighted reward: 0.128883, Std dev weighted reward: 0.131300\n",
      "Maximum episode length 200, Average episode length: 199.110000, Std dev episode length: 4.865994\n",
      "Maximum actual reward -154, Average actual rewards: -199.110000, Std dev actual rewards: 4.865994\n",
      "Maximum height 0.524668, Average height: -0.501422, Std dev height: 0.356179\n",
      "Maximum velocity 0.049294, Average velocity: 0.015885, Std dev velocity: 0.011934\n",
      "-----------------------------------------------------\n",
      "-0.381512\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3000--------------------------\n",
      "Maximum weighted reward 0.291396, Average weighted reward: 0.133664, Std dev weighted reward: 0.150790\n",
      "Maximum episode length 200, Average episode length: 198.830000, Std dev episode length: 3.143422\n",
      "Maximum actual reward -181, Average actual rewards: -198.830000, Std dev actual rewards: 3.143422\n",
      "Maximum height 0.532371, Average height: -0.504528, Std dev height: 0.357158\n",
      "Maximum velocity 0.050597, Average velocity: 0.015636, Std dev velocity: 0.012107\n",
      "-----------------------------------------------------\n",
      "-0.410724\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3100--------------------------\n",
      "Maximum weighted reward 0.293287, Average weighted reward: 0.105527, Std dev weighted reward: 0.148211\n",
      "Maximum episode length 200, Average episode length: 198.750000, Std dev episode length: 9.766652\n",
      "Maximum actual reward -103, Average actual rewards: -198.750000, Std dev actual rewards: 9.766652\n",
      "Maximum height 0.531176, Average height: -0.523290, Std dev height: 0.336762\n",
      "Maximum velocity 0.055397, Average velocity: 0.015051, Std dev velocity: 0.011708\n",
      "-----------------------------------------------------\n",
      "-0.389872\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3200--------------------------\n",
      "Maximum weighted reward 0.287016, Average weighted reward: 0.076792, Std dev weighted reward: 0.159998\n",
      "Maximum episode length 200, Average episode length: 199.760000, Std dev episode length: 1.096540\n",
      "Maximum actual reward -193, Average actual rewards: -199.760000, Std dev actual rewards: 1.096540\n",
      "Maximum height 0.524578, Average height: -0.542986, Std dev height: 0.323867\n",
      "Maximum velocity 0.051612, Average velocity: 0.014671, Std dev velocity: 0.011104\n",
      "-----------------------------------------------------\n",
      "-0.410567\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3300--------------------------\n",
      "Maximum weighted reward 0.296039, Average weighted reward: 0.139158, Std dev weighted reward: 0.165020\n",
      "Maximum episode length 200, Average episode length: 197.700000, Std dev episode length: 9.429210\n",
      "Maximum actual reward -108, Average actual rewards: -197.700000, Std dev actual rewards: 9.429210\n",
      "Maximum height 0.536096, Average height: -0.515907, Std dev height: 0.340059\n",
      "Maximum velocity 0.060442, Average velocity: 0.015255, Std dev velocity: 0.012158\n",
      "-----------------------------------------------------\n",
      "-0.506989\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3400--------------------------\n",
      "Maximum weighted reward 0.291347, Average weighted reward: 0.084316, Std dev weighted reward: 0.156182\n",
      "Maximum episode length 200, Average episode length: 199.700000, Std dev episode length: 1.493318\n",
      "Maximum actual reward -189, Average actual rewards: -199.700000, Std dev actual rewards: 1.493318\n",
      "Maximum height 0.530212, Average height: -0.531996, Std dev height: 0.315890\n",
      "Maximum velocity 0.056201, Average velocity: 0.014072, Std dev velocity: 0.010928\n",
      "-----------------------------------------------------\n",
      "-0.596337\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3500--------------------------\n",
      "Maximum weighted reward 0.295179, Average weighted reward: 0.132764, Std dev weighted reward: 0.177187\n",
      "Maximum episode length 200, Average episode length: 197.690000, Std dev episode length: 5.072859\n",
      "Maximum actual reward -168, Average actual rewards: -197.690000, Std dev actual rewards: 5.072859\n",
      "Maximum height 0.537156, Average height: -0.542348, Std dev height: 0.344670\n",
      "Maximum velocity 0.056655, Average velocity: 0.015468, Std dev velocity: 0.012429\n",
      "-----------------------------------------------------\n",
      "-0.674624\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3600--------------------------\n",
      "Maximum weighted reward 0.291559, Average weighted reward: 0.141389, Std dev weighted reward: 0.145611\n",
      "Maximum episode length 200, Average episode length: 198.930000, Std dev episode length: 2.425923\n",
      "Maximum actual reward -189, Average actual rewards: -198.930000, Std dev actual rewards: 2.425923\n",
      "Maximum height 0.531370, Average height: -0.539348, Std dev height: 0.351334\n",
      "Maximum velocity 0.054138, Average velocity: 0.016006, Std dev velocity: 0.012610\n",
      "-----------------------------------------------------\n",
      "-0.738883\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3700--------------------------\n",
      "Maximum weighted reward 0.291340, Average weighted reward: 0.135442, Std dev weighted reward: 0.172478\n",
      "Maximum episode length 200, Average episode length: 198.100000, Std dev episode length: 3.742993\n",
      "Maximum actual reward -184, Average actual rewards: -198.100000, Std dev actual rewards: 3.742993\n",
      "Maximum height 0.530944, Average height: -0.544439, Std dev height: 0.352994\n",
      "Maximum velocity 0.053397, Average velocity: 0.015930, Std dev velocity: 0.012242\n",
      "-----------------------------------------------------\n",
      "-0.78335\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3800--------------------------\n",
      "Maximum weighted reward 0.287352, Average weighted reward: 0.109037, Std dev weighted reward: 0.164043\n",
      "Maximum episode length 200, Average episode length: 199.220000, Std dev episode length: 2.229709\n",
      "Maximum actual reward -188, Average actual rewards: -199.220000, Std dev actual rewards: 2.229709\n",
      "Maximum height 0.526898, Average height: -0.557207, Std dev height: 0.337531\n",
      "Maximum velocity 0.050935, Average velocity: 0.015209, Std dev velocity: 0.011449\n",
      "-----------------------------------------------------\n",
      "-0.871576\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 3900--------------------------\n",
      "Maximum weighted reward 0.289723, Average weighted reward: 0.116135, Std dev weighted reward: 0.150725\n",
      "Maximum episode length 200, Average episode length: 199.460000, Std dev episode length: 1.951512\n",
      "Maximum actual reward -185, Average actual rewards: -199.460000, Std dev actual rewards: 1.951512\n",
      "Maximum height 0.529759, Average height: -0.555098, Std dev height: 0.330761\n",
      "Maximum velocity 0.049842, Average velocity: 0.015026, Std dev velocity: 0.011867\n",
      "-----------------------------------------------------\n",
      "-0.945777\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4000--------------------------\n",
      "Maximum weighted reward 0.284043, Average weighted reward: 0.116633, Std dev weighted reward: 0.138974\n",
      "Maximum episode length 200, Average episode length: 199.560000, Std dev episode length: 1.940722\n",
      "Maximum actual reward -184, Average actual rewards: -199.560000, Std dev actual rewards: 1.940722\n",
      "Maximum height 0.521929, Average height: -0.553233, Std dev height: 0.333199\n",
      "Maximum velocity 0.049976, Average velocity: 0.015276, Std dev velocity: 0.011948\n",
      "-----------------------------------------------------\n",
      "-0.988664\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4100--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum weighted reward 0.287914, Average weighted reward: 0.117676, Std dev weighted reward: 0.141817\n",
      "Maximum episode length 200, Average episode length: 199.460000, Std dev episode length: 1.615054\n",
      "Maximum actual reward -192, Average actual rewards: -199.460000, Std dev actual rewards: 1.615054\n",
      "Maximum height 0.527997, Average height: -0.542061, Std dev height: 0.338692\n",
      "Maximum velocity 0.051143, Average velocity: 0.015334, Std dev velocity: 0.011890\n",
      "-----------------------------------------------------\n",
      "-0.976457\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4200--------------------------\n",
      "Maximum weighted reward 0.281566, Average weighted reward: 0.081962, Std dev weighted reward: 0.133440\n",
      "Maximum episode length 200, Average episode length: 199.790000, Std dev episode length: 1.733753\n",
      "Maximum actual reward -183, Average actual rewards: -199.790000, Std dev actual rewards: 1.733753\n",
      "Maximum height 0.516098, Average height: -0.551136, Std dev height: 0.330317\n",
      "Maximum velocity 0.049728, Average velocity: 0.015325, Std dev velocity: 0.011643\n",
      "-----------------------------------------------------\n",
      "-0.996618\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4300--------------------------\n",
      "Maximum weighted reward 0.278966, Average weighted reward: 0.010988, Std dev weighted reward: 0.170719\n",
      "Maximum episode length 200, Average episode length: 199.670000, Std dev episode length: 2.271805\n",
      "Maximum actual reward -178, Average actual rewards: -199.670000, Std dev actual rewards: 2.271805\n",
      "Maximum height 0.513846, Average height: -0.558841, Std dev height: 0.291758\n",
      "Maximum velocity 0.049994, Average velocity: 0.012898, Std dev velocity: 0.010360\n",
      "-----------------------------------------------------\n",
      "-0.955214\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4400--------------------------\n",
      "Maximum weighted reward 0.284961, Average weighted reward: 0.081045, Std dev weighted reward: 0.155963\n",
      "Maximum episode length 200, Average episode length: 199.500000, Std dev episode length: 1.571623\n",
      "Maximum actual reward -192, Average actual rewards: -199.500000, Std dev actual rewards: 1.571623\n",
      "Maximum height 0.524738, Average height: -0.527394, Std dev height: 0.327887\n",
      "Maximum velocity 0.048420, Average velocity: 0.014366, Std dev velocity: 0.011405\n",
      "-----------------------------------------------------\n",
      "-0.94922\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4500--------------------------\n",
      "Maximum weighted reward 0.287352, Average weighted reward: 0.046005, Std dev weighted reward: 0.157977\n",
      "Maximum episode length 200, Average episode length: 199.640000, Std dev episode length: 1.957141\n",
      "Maximum actual reward -183, Average actual rewards: -199.640000, Std dev actual rewards: 1.957141\n",
      "Maximum height 0.526898, Average height: -0.523965, Std dev height: 0.310818\n",
      "Maximum velocity 0.048081, Average velocity: 0.014060, Std dev velocity: 0.010902\n",
      "-----------------------------------------------------\n",
      "-0.918365\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4600--------------------------\n",
      "Maximum weighted reward 0.278228, Average weighted reward: 0.035740, Std dev weighted reward: 0.153738\n",
      "Maximum episode length 200, Average episode length: 199.860000, Std dev episode length: 0.787655\n",
      "Maximum actual reward -194, Average actual rewards: -199.860000, Std dev actual rewards: 0.787655\n",
      "Maximum height 0.510903, Average height: -0.538146, Std dev height: 0.301369\n",
      "Maximum velocity 0.048706, Average velocity: 0.013542, Std dev velocity: 0.010804\n",
      "-----------------------------------------------------\n",
      "-0.903901\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4700--------------------------\n",
      "Maximum weighted reward 0.281184, Average weighted reward: 0.064174, Std dev weighted reward: 0.159376\n",
      "Maximum episode length 200, Average episode length: 199.550000, Std dev episode length: 1.925487\n",
      "Maximum actual reward -189, Average actual rewards: -199.550000, Std dev actual rewards: 1.925487\n",
      "Maximum height 0.516331, Average height: -0.528733, Std dev height: 0.319327\n",
      "Maximum velocity 0.049713, Average velocity: 0.014276, Std dev velocity: 0.010957\n",
      "-----------------------------------------------------\n",
      "-0.930825\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4800--------------------------\n",
      "Maximum weighted reward 0.276864, Average weighted reward: 0.037809, Std dev weighted reward: 0.152655\n",
      "Maximum episode length 200, Average episode length: 199.930000, Std dev episode length: 0.604235\n",
      "Maximum actual reward -194, Average actual rewards: -199.930000, Std dev actual rewards: 0.604235\n",
      "Maximum height 0.510212, Average height: -0.528839, Std dev height: 0.308361\n",
      "Maximum velocity 0.047822, Average velocity: 0.013634, Std dev velocity: 0.010805\n",
      "-----------------------------------------------------\n",
      "-0.961077\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 4900--------------------------\n",
      "Maximum weighted reward 0.230691, Average weighted reward: 0.010841, Std dev weighted reward: 0.125083\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.416221, Average height: -0.524209, Std dev height: 0.280653\n",
      "Maximum velocity 0.046401, Average velocity: 0.012389, Std dev velocity: 0.010001\n",
      "-----------------------------------------------------\n",
      "-0.993845\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5000--------------------------\n",
      "Maximum weighted reward 0.207904, Average weighted reward: -0.022305, Std dev weighted reward: 0.152682\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.371374, Average height: -0.556702, Std dev height: 0.277286\n",
      "Maximum velocity 0.045185, Average velocity: 0.012545, Std dev velocity: 0.009839\n",
      "-----------------------------------------------------\n",
      "-0.990007\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5100--------------------------\n",
      "Maximum weighted reward 0.266934, Average weighted reward: 0.010884, Std dev weighted reward: 0.136601\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.490393, Average height: -0.526943, Std dev height: 0.301537\n",
      "Maximum velocity 0.046747, Average velocity: 0.013399, Std dev velocity: 0.010679\n",
      "-----------------------------------------------------\n",
      "-1.06239\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5200--------------------------\n",
      "Maximum weighted reward 0.276476, Average weighted reward: 0.004393, Std dev weighted reward: 0.148262\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.511042, Average height: -0.540725, Std dev height: 0.282075\n",
      "Maximum velocity 0.046664, Average velocity: 0.012386, Std dev velocity: 0.010288\n",
      "-----------------------------------------------------\n",
      "-1.02723\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5300--------------------------\n",
      "Maximum weighted reward 0.051823, Average weighted reward: -0.106529, Std dev weighted reward: 0.105360\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.069437, Average height: -0.591192, Std dev height: 0.212885\n",
      "Maximum velocity 0.037936, Average velocity: 0.010588, Std dev velocity: 0.007672\n",
      "-----------------------------------------------------\n",
      "-1.06828\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5400--------------------------\n",
      "Maximum weighted reward 0.220223, Average weighted reward: -0.084263, Std dev weighted reward: 0.149242\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.398093, Average height: -0.587648, Std dev height: 0.243712\n",
      "Maximum velocity 0.045217, Average velocity: 0.011243, Std dev velocity: 0.009051\n",
      "-----------------------------------------------------\n",
      "-1.03144\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Iteration 5500--------------------------\n",
      "Maximum weighted reward 0.154473, Average weighted reward: -0.054805, Std dev weighted reward: 0.122071\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.268045, Average height: -0.562479, Std dev height: 0.250644\n",
      "Maximum velocity 0.040902, Average velocity: 0.011697, Std dev velocity: 0.009133\n",
      "-----------------------------------------------------\n",
      "-1.08942\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5600--------------------------\n",
      "Maximum weighted reward 0.185116, Average weighted reward: -0.092411, Std dev weighted reward: 0.134857\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.323167, Average height: -0.575982, Std dev height: 0.231592\n",
      "Maximum velocity 0.047066, Average velocity: 0.010551, Std dev velocity: 0.008836\n",
      "-----------------------------------------------------\n",
      "-1.12055\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5700--------------------------\n",
      "Maximum weighted reward -0.031613, Average weighted reward: -0.201826, Std dev weighted reward: 0.086347\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.091312, Average height: -0.617103, Std dev height: 0.168335\n",
      "Maximum velocity 0.030645, Average velocity: 0.007905, Std dev velocity: 0.005656\n",
      "-----------------------------------------------------\n",
      "-1.34274\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5800--------------------------\n",
      "Maximum weighted reward -0.029856, Average weighted reward: -0.241018, Std dev weighted reward: 0.074439\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.091324, Average height: -0.660904, Std dev height: 0.142059\n",
      "Maximum velocity 0.031612, Average velocity: 0.008510, Std dev velocity: 0.005517\n",
      "-----------------------------------------------------\n",
      "-1.32685\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 5900--------------------------\n",
      "Maximum weighted reward -0.035261, Average weighted reward: -0.208168, Std dev weighted reward: 0.084486\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.100591, Average height: -0.633123, Std dev height: 0.170704\n",
      "Maximum velocity 0.030069, Average velocity: 0.008707, Std dev velocity: 0.005743\n",
      "-----------------------------------------------------\n",
      "-1.35792\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6000--------------------------\n",
      "Maximum weighted reward -0.026887, Average weighted reward: -0.207450, Std dev weighted reward: 0.090281\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.088853, Average height: -0.638753, Std dev height: 0.166056\n",
      "Maximum velocity 0.035080, Average velocity: 0.008360, Std dev velocity: 0.006206\n",
      "-----------------------------------------------------\n",
      "-1.2334\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6100--------------------------\n",
      "Maximum weighted reward -0.048892, Average weighted reward: -0.186899, Std dev weighted reward: 0.082554\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.123970, Average height: -0.519674, Std dev height: 0.173848\n",
      "Maximum velocity 0.027371, Average velocity: 0.005667, Std dev velocity: 0.004792\n",
      "-----------------------------------------------------\n",
      "-1.32447\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6200--------------------------\n",
      "Maximum weighted reward -0.050825, Average weighted reward: -0.204208, Std dev weighted reward: 0.077418\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.134123, Average height: -0.539958, Std dev height: 0.168053\n",
      "Maximum velocity 0.032472, Average velocity: 0.005254, Std dev velocity: 0.004432\n",
      "-----------------------------------------------------\n",
      "-1.31963\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6300--------------------------\n",
      "Maximum weighted reward 0.288461, Average weighted reward: 0.224298, Std dev weighted reward: 0.064951\n",
      "Maximum episode length 200, Average episode length: 197.320000, Std dev episode length: 9.125656\n",
      "Maximum actual reward -113, Average actual rewards: -197.320000, Std dev actual rewards: 9.125656\n",
      "Maximum height 0.529016, Average height: -0.501249, Std dev height: 0.414730\n",
      "Maximum velocity 0.055968, Average velocity: 0.019292, Std dev velocity: 0.013310\n",
      "-----------------------------------------------------\n",
      "-0.962831\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6400--------------------------\n",
      "Maximum weighted reward 0.093996, Average weighted reward: -0.046686, Std dev weighted reward: 0.102423\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.147313, Average height: -0.588399, Std dev height: 0.280823\n",
      "Maximum velocity 0.046239, Average velocity: 0.013414, Std dev velocity: 0.010013\n",
      "-----------------------------------------------------\n",
      "-1.13968\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6500--------------------------\n",
      "Maximum weighted reward 0.287627, Average weighted reward: 0.229008, Std dev weighted reward: 0.071671\n",
      "Maximum episode length 200, Average episode length: 190.410000, Std dev episode length: 22.000043\n",
      "Maximum actual reward -107, Average actual rewards: -190.410000, Std dev actual rewards: 22.000043\n",
      "Maximum height 0.525496, Average height: -0.464611, Std dev height: 0.432419\n",
      "Maximum velocity 0.056352, Average velocity: 0.019833, Std dev velocity: 0.014058\n",
      "-----------------------------------------------------\n",
      "-0.955621\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6600--------------------------\n",
      "Maximum weighted reward 0.288108, Average weighted reward: 0.205690, Std dev weighted reward: 0.121494\n",
      "Maximum episode length 200, Average episode length: 180.430000, Std dev episode length: 30.334553\n",
      "Maximum actual reward -99, Average actual rewards: -180.430000, Std dev actual rewards: 30.334553\n",
      "Maximum height 0.526006, Average height: -0.462169, Std dev height: 0.427041\n",
      "Maximum velocity 0.055114, Average velocity: 0.018484, Std dev velocity: 0.013860\n",
      "-----------------------------------------------------\n",
      "-1.0043\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6700--------------------------\n",
      "Maximum weighted reward 0.286871, Average weighted reward: 0.192485, Std dev weighted reward: 0.105656\n",
      "Maximum episode length 200, Average episode length: 193.350000, Std dev episode length: 18.863390\n",
      "Maximum actual reward -102, Average actual rewards: -193.350000, Std dev actual rewards: 18.863390\n",
      "Maximum height 0.527005, Average height: -0.506108, Std dev height: 0.398485\n",
      "Maximum velocity 0.052841, Average velocity: 0.017314, Std dev velocity: 0.012594\n",
      "-----------------------------------------------------\n",
      "-0.980988\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6800--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum weighted reward 0.282342, Average weighted reward: -0.033518, Std dev weighted reward: 0.152876\n",
      "Maximum episode length 200, Average episode length: 199.960000, Std dev episode length: 0.397995\n",
      "Maximum actual reward -196, Average actual rewards: -199.960000, Std dev actual rewards: 0.397995\n",
      "Maximum height 0.518522, Average height: -0.537944, Std dev height: 0.261070\n",
      "Maximum velocity 0.047202, Average velocity: 0.011459, Std dev velocity: 0.009782\n",
      "-----------------------------------------------------\n",
      "-1.07374\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 6900--------------------------\n",
      "Maximum weighted reward 0.254351, Average weighted reward: -0.046297, Std dev weighted reward: 0.156450\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.462877, Average height: -0.551854, Std dev height: 0.257025\n",
      "Maximum velocity 0.046664, Average velocity: 0.011478, Std dev velocity: 0.009482\n",
      "-----------------------------------------------------\n",
      "-1.11493\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7000--------------------------\n",
      "Maximum weighted reward -0.063101, Average weighted reward: -0.242808, Std dev weighted reward: 0.070783\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.151967, Average height: -0.655395, Std dev height: 0.134896\n",
      "Maximum velocity 0.028330, Average velocity: 0.007901, Std dev velocity: 0.005112\n",
      "-----------------------------------------------------\n",
      "-1.37244\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7100--------------------------\n",
      "Maximum weighted reward -0.043765, Average weighted reward: -0.234381, Std dev weighted reward: 0.075951\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.109294, Average height: -0.647753, Std dev height: 0.145826\n",
      "Maximum velocity 0.028877, Average velocity: 0.007852, Std dev velocity: 0.005361\n",
      "-----------------------------------------------------\n",
      "-1.37531\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7200--------------------------\n",
      "Maximum weighted reward -0.036308, Average weighted reward: -0.222086, Std dev weighted reward: 0.083124\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.104679, Average height: -0.650414, Std dev height: 0.158050\n",
      "Maximum velocity 0.032477, Average velocity: 0.008675, Std dev velocity: 0.005914\n",
      "-----------------------------------------------------\n",
      "-1.32577\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7300--------------------------\n",
      "Maximum weighted reward -0.019290, Average weighted reward: -0.242887, Std dev weighted reward: 0.082041\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.072760, Average height: -0.653154, Std dev height: 0.137470\n",
      "Maximum velocity 0.034181, Average velocity: 0.007263, Std dev velocity: 0.005623\n",
      "-----------------------------------------------------\n",
      "-1.32877\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7400--------------------------\n",
      "Maximum weighted reward 0.130966, Average weighted reward: -0.129450, Std dev weighted reward: 0.137719\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.223103, Average height: -0.599770, Std dev height: 0.226791\n",
      "Maximum velocity 0.042841, Average velocity: 0.010693, Std dev velocity: 0.009080\n",
      "-----------------------------------------------------\n",
      "-1.07076\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7500--------------------------\n",
      "Maximum weighted reward 0.142893, Average weighted reward: -0.111359, Std dev weighted reward: 0.121502\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.245139, Average height: -0.570009, Std dev height: 0.209291\n",
      "Maximum velocity 0.042547, Average velocity: 0.009832, Std dev velocity: 0.008291\n",
      "-----------------------------------------------------\n",
      "-1.18386\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7600--------------------------\n",
      "Maximum weighted reward 0.114377, Average weighted reward: -0.056553, Std dev weighted reward: 0.104949\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.192964, Average height: -0.572870, Std dev height: 0.253111\n",
      "Maximum velocity 0.043884, Average velocity: 0.012226, Std dev velocity: 0.008870\n",
      "-----------------------------------------------------\n",
      "-1.26293\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7700--------------------------\n",
      "Maximum weighted reward 0.066941, Average weighted reward: -0.127566, Std dev weighted reward: 0.100747\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.100598, Average height: -0.590864, Std dev height: 0.202184\n",
      "Maximum velocity 0.037409, Average velocity: 0.010106, Std dev velocity: 0.007346\n",
      "-----------------------------------------------------\n",
      "-1.3239\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7800--------------------------\n",
      "Maximum weighted reward 0.097051, Average weighted reward: -0.142243, Std dev weighted reward: 0.141411\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height 0.156045, Average height: -0.640259, Std dev height: 0.220159\n",
      "Maximum velocity 0.040774, Average velocity: 0.010530, Std dev velocity: 0.008503\n",
      "-----------------------------------------------------\n",
      "-1.51353\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 7900--------------------------\n",
      "Maximum weighted reward 0.283882, Average weighted reward: 0.209690, Std dev weighted reward: 0.093002\n",
      "Maximum episode length 200, Average episode length: 199.610000, Std dev episode length: 1.156676\n",
      "Maximum actual reward -194, Average actual rewards: -199.610000, Std dev actual rewards: 1.156676\n",
      "Maximum height 0.521495, Average height: -0.513314, Std dev height: 0.400134\n",
      "Maximum velocity 0.052086, Average velocity: 0.018888, Std dev velocity: 0.013033\n",
      "-----------------------------------------------------\n",
      "-1.30396\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8000--------------------------\n",
      "Maximum weighted reward 0.289723, Average weighted reward: 0.224655, Std dev weighted reward: 0.071499\n",
      "Maximum episode length 200, Average episode length: 196.700000, Std dev episode length: 9.847335\n",
      "Maximum actual reward -120, Average actual rewards: -196.700000, Std dev actual rewards: 9.847335\n",
      "Maximum height 0.529759, Average height: -0.491254, Std dev height: 0.418692\n",
      "Maximum velocity 0.053488, Average velocity: 0.019958, Std dev velocity: 0.013784\n",
      "-----------------------------------------------------\n",
      "-1.307\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8100--------------------------\n",
      "Maximum weighted reward 0.284495, Average weighted reward: 0.209625, Std dev weighted reward: 0.065550\n",
      "Maximum episode length 200, Average episode length: 197.620000, Std dev episode length: 11.092141\n",
      "Maximum actual reward -117, Average actual rewards: -197.620000, Std dev actual rewards: 11.092141\n",
      "Maximum height 0.521977, Average height: -0.498295, Std dev height: 0.410031\n",
      "Maximum velocity 0.051840, Average velocity: 0.019257, Std dev velocity: 0.013169\n",
      "-----------------------------------------------------\n",
      "-1.28924\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Iteration 8200--------------------------\n",
      "Maximum weighted reward -0.061286, Average weighted reward: -0.228699, Std dev weighted reward: 0.080342\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.149463, Average height: -0.612090, Std dev height: 0.160689\n",
      "Maximum velocity 0.029612, Average velocity: 0.006809, Std dev velocity: 0.005053\n",
      "-----------------------------------------------------\n",
      "-1.56866\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8300--------------------------\n",
      "Maximum weighted reward 0.012524, Average weighted reward: -0.154080, Std dev weighted reward: 0.077203\n",
      "Maximum episode length 200, Average episode length: 200.000000, Std dev episode length: 0.000000\n",
      "Maximum actual reward -200, Average actual rewards: -200.000000, Std dev actual rewards: 0.000000\n",
      "Maximum height -0.015879, Average height: -0.501676, Std dev height: 0.193807\n",
      "Maximum velocity 0.040928, Average velocity: 0.006921, Std dev velocity: 0.006728\n",
      "-----------------------------------------------------\n",
      "-1.52082\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8400--------------------------\n",
      "Maximum weighted reward 0.284294, Average weighted reward: 0.192307, Std dev weighted reward: 0.071527\n",
      "Maximum episode length 200, Average episode length: 199.360000, Std dev episode length: 1.936595\n",
      "Maximum actual reward -189, Average actual rewards: -199.360000, Std dev actual rewards: 1.936595\n",
      "Maximum height 0.521949, Average height: -0.527016, Std dev height: 0.403239\n",
      "Maximum velocity 0.054412, Average velocity: 0.018057, Std dev velocity: 0.012494\n",
      "-----------------------------------------------------\n",
      "-1.32846\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8500--------------------------\n",
      "Maximum weighted reward 0.287449, Average weighted reward: 0.258268, Std dev weighted reward: 0.032925\n",
      "Maximum episode length 200, Average episode length: 196.320000, Std dev episode length: 9.565438\n",
      "Maximum actual reward -111, Average actual rewards: -196.320000, Std dev actual rewards: 9.565438\n",
      "Maximum height 0.522882, Average height: -0.487264, Std dev height: 0.423799\n",
      "Maximum velocity 0.056851, Average velocity: 0.020423, Std dev velocity: 0.014235\n",
      "-----------------------------------------------------\n",
      "-1.36217\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8600--------------------------\n",
      "Maximum weighted reward 0.283080, Average weighted reward: 0.224304, Std dev weighted reward: 0.075615\n",
      "Maximum episode length 200, Average episode length: 198.140000, Std dev episode length: 3.289438\n",
      "Maximum actual reward -188, Average actual rewards: -198.140000, Std dev actual rewards: 3.289438\n",
      "Maximum height 0.521977, Average height: -0.516865, Std dev height: 0.408706\n",
      "Maximum velocity 0.056824, Average velocity: 0.019046, Std dev velocity: 0.013201\n",
      "-----------------------------------------------------\n",
      "-1.37509\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8700--------------------------\n",
      "Maximum weighted reward 0.290946, Average weighted reward: 0.253692, Std dev weighted reward: 0.050065\n",
      "Maximum episode length 200, Average episode length: 196.480000, Std dev episode length: 4.087738\n",
      "Maximum actual reward -186, Average actual rewards: -196.480000, Std dev actual rewards: 4.087738\n",
      "Maximum height 0.529016, Average height: -0.499157, Std dev height: 0.423697\n",
      "Maximum velocity 0.057217, Average velocity: 0.020125, Std dev velocity: 0.013768\n",
      "-----------------------------------------------------\n",
      "-1.37731\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8800--------------------------\n",
      "Maximum weighted reward 0.293294, Average weighted reward: 0.266512, Std dev weighted reward: 0.026116\n",
      "Maximum episode length 200, Average episode length: 193.100000, Std dev episode length: 7.918965\n",
      "Maximum actual reward -139, Average actual rewards: -193.100000, Std dev actual rewards: 7.918965\n",
      "Maximum height 0.527640, Average height: -0.470821, Std dev height: 0.443337\n",
      "Maximum velocity 0.062234, Average velocity: 0.021277, Std dev velocity: 0.015349\n",
      "-----------------------------------------------------\n",
      "-1.38235\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 8900--------------------------\n",
      "Maximum weighted reward 0.286160, Average weighted reward: 0.248316, Std dev weighted reward: 0.037414\n",
      "Maximum episode length 200, Average episode length: 197.700000, Std dev episode length: 4.191658\n",
      "Maximum actual reward -185, Average actual rewards: -197.700000, Std dev actual rewards: 4.191658\n",
      "Maximum height 0.514214, Average height: -0.437999, Std dev height: 0.463318\n",
      "Maximum velocity 0.067949, Average velocity: 0.021154, Std dev velocity: 0.016337\n",
      "-----------------------------------------------------\n",
      "-1.33566\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9000--------------------------\n",
      "Maximum weighted reward 0.287929, Average weighted reward: 0.266015, Std dev weighted reward: 0.017185\n",
      "Maximum episode length 200, Average episode length: 195.400000, Std dev episode length: 6.876045\n",
      "Maximum actual reward -148, Average actual rewards: -195.400000, Std dev actual rewards: 6.876045\n",
      "Maximum height 0.518732, Average height: -0.437241, Std dev height: 0.464442\n",
      "Maximum velocity 0.064449, Average velocity: 0.021823, Std dev velocity: 0.016531\n",
      "-----------------------------------------------------\n",
      "-1.3501\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9100--------------------------\n",
      "Maximum weighted reward 0.285876, Average weighted reward: 0.245280, Std dev weighted reward: 0.038131\n",
      "Maximum episode length 200, Average episode length: 197.160000, Std dev episode length: 5.622668\n",
      "Maximum actual reward -179, Average actual rewards: -197.160000, Std dev actual rewards: 5.622668\n",
      "Maximum height 0.512758, Average height: -0.411751, Std dev height: 0.479824\n",
      "Maximum velocity 0.066441, Average velocity: 0.022076, Std dev velocity: 0.017047\n",
      "-----------------------------------------------------\n",
      "-1.30639\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9200--------------------------\n",
      "Maximum weighted reward 0.282409, Average weighted reward: 0.245021, Std dev weighted reward: 0.019264\n",
      "Maximum episode length 200, Average episode length: 199.370000, Std dev episode length: 2.305016\n",
      "Maximum actual reward -187, Average actual rewards: -199.370000, Std dev actual rewards: 2.305016\n",
      "Maximum height 0.509010, Average height: -0.447219, Std dev height: 0.456072\n",
      "Maximum velocity 0.061103, Average velocity: 0.020615, Std dev velocity: 0.015847\n",
      "-----------------------------------------------------\n",
      "-1.37074\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9300--------------------------\n",
      "Maximum weighted reward 0.285360, Average weighted reward: 0.249938, Std dev weighted reward: 0.020794\n",
      "Maximum episode length 200, Average episode length: 198.380000, Std dev episode length: 3.979397\n",
      "Maximum actual reward -183, Average actual rewards: -198.380000, Std dev actual rewards: 3.979397\n",
      "Maximum height 0.512758, Average height: -0.421863, Std dev height: 0.471369\n",
      "Maximum velocity 0.063506, Average velocity: 0.021301, Std dev velocity: 0.016650\n",
      "-----------------------------------------------------\n",
      "-1.33323\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9400--------------------------\n",
      "Maximum weighted reward 0.286257, Average weighted reward: 0.237308, Std dev weighted reward: 0.021805\n",
      "Maximum episode length 200, Average episode length: 199.560000, Std dev episode length: 2.011567\n",
      "Maximum actual reward -187, Average actual rewards: -199.560000, Std dev actual rewards: 2.011567\n",
      "Maximum height 0.512758, Average height: -0.426828, Std dev height: 0.467701\n",
      "Maximum velocity 0.063531, Average velocity: 0.021192, Std dev velocity: 0.016435\n",
      "-----------------------------------------------------\n",
      "-1.36152\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9500--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum weighted reward 0.281541, Average weighted reward: 0.241731, Std dev weighted reward: 0.020802\n",
      "Maximum episode length 200, Average episode length: 199.630000, Std dev episode length: 1.566238\n",
      "Maximum actual reward -188, Average actual rewards: -199.630000, Std dev actual rewards: 1.566238\n",
      "Maximum height 0.510315, Average height: -0.436056, Std dev height: 0.463517\n",
      "Maximum velocity 0.063115, Average velocity: 0.020900, Std dev velocity: 0.016228\n",
      "-----------------------------------------------------\n",
      "-1.35743\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9600--------------------------\n",
      "Maximum weighted reward 0.284253, Average weighted reward: 0.260250, Std dev weighted reward: 0.031991\n",
      "Maximum episode length 200, Average episode length: 196.780000, Std dev episode length: 5.181853\n",
      "Maximum actual reward -181, Average actual rewards: -196.780000, Std dev actual rewards: 5.181853\n",
      "Maximum height 0.514238, Average height: -0.426889, Std dev height: 0.471385\n",
      "Maximum velocity 0.065592, Average velocity: 0.022185, Std dev velocity: 0.016630\n",
      "-----------------------------------------------------\n",
      "-1.35332\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9700--------------------------\n",
      "Maximum weighted reward 0.285400, Average weighted reward: 0.243077, Std dev weighted reward: 0.021291\n",
      "Maximum episode length 200, Average episode length: 199.280000, Std dev episode length: 2.370991\n",
      "Maximum actual reward -189, Average actual rewards: -199.280000, Std dev actual rewards: 2.370991\n",
      "Maximum height 0.509718, Average height: -0.420579, Std dev height: 0.473518\n",
      "Maximum velocity 0.062486, Average velocity: 0.021704, Std dev velocity: 0.016561\n",
      "-----------------------------------------------------\n",
      "-1.32409\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9800--------------------------\n",
      "Maximum weighted reward 0.284295, Average weighted reward: 0.262876, Std dev weighted reward: 0.017635\n",
      "Maximum episode length 200, Average episode length: 196.980000, Std dev episode length: 5.775777\n",
      "Maximum actual reward -177, Average actual rewards: -196.980000, Std dev actual rewards: 5.775777\n",
      "Maximum height 0.509275, Average height: -0.406555, Std dev height: 0.480864\n",
      "Maximum velocity 0.060681, Average velocity: 0.022044, Std dev velocity: 0.017173\n",
      "-----------------------------------------------------\n",
      "-1.30784\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9900--------------------------\n",
      "Maximum weighted reward 0.284499, Average weighted reward: 0.251151, Std dev weighted reward: 0.024512\n",
      "Maximum episode length 200, Average episode length: 198.500000, Std dev episode length: 4.272002\n",
      "Maximum actual reward -181, Average actual rewards: -198.500000, Std dev actual rewards: 4.272002\n",
      "Maximum height 0.512356, Average height: -0.397328, Std dev height: 0.487517\n",
      "Maximum velocity 0.061848, Average velocity: 0.022017, Std dev velocity: 0.017189\n",
      "-----------------------------------------------------\n",
      "-1.26702\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n",
      "------------------Iteration 9999--------------------------\n",
      "Maximum weighted reward 0.279377, Average weighted reward: 0.240710, Std dev weighted reward: 0.021649\n",
      "Maximum episode length 200, Average episode length: 199.830000, Std dev episode length: 1.192099\n",
      "Maximum actual reward -191, Average actual rewards: -199.830000, Std dev actual rewards: 1.192099\n",
      "Maximum height 0.502786, Average height: -0.410704, Std dev height: 0.479061\n",
      "Maximum velocity 0.062128, Average velocity: 0.021548, Std dev velocity: 0.016951\n",
      "-----------------------------------------------------\n",
      "-1.27117\n",
      "Model saved in file: /tmp/mountain_car_pg.chkpt\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_iterations': 10000,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'discount_gamma': 0.99,\n",
    "    'num_hidden': 32,\n",
    "}\n",
    "\n",
    "def do_training(agent, sess):\n",
    "    average_rewards = []\n",
    "    for i in xrange(config['num_iterations']):\n",
    "        print_summary = (i > 0 and i % 100 == 0) or i == config[\"num_iterations\"] - 1\n",
    "        if print_summary:\n",
    "            print(\"------------------Iteration %d--------------------------\" % i)\n",
    "\n",
    "        avg_reward = run_single_iteration(\n",
    "            sess,\n",
    "            batch_size=config['batch_size'],\n",
    "            discount_gamma=config['discount_gamma'],\n",
    "            print_summary=print_summary,\n",
    "        )\n",
    "        average_rewards.append(avg_reward)\n",
    "        if print_summary:\n",
    "            print(\"-----------------------------------------------------\")\n",
    "        if (i > 0 and i % 100 == 0) or i == config[\"num_iterations\"] - 1:\n",
    "            save_path = agent.save(sess, \"/tmp/mountain_car_pg.chkpt\")\n",
    "            print(agent.params[0][0][0])\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    return np.array(average_rewards)\n",
    "    \n",
    "    \n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    tf_session = sess\n",
    "    agent = PolicyGradientAgent(env, learning_rate=config['learning_rate'], num_hidden=config['num_hidden'])\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    agent.set_params(sess.run([agent.W0, agent.b0, agent.W1, agent.b1]))\n",
    "    \n",
    "    average_rewards = do_training(agent, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,u'Average reward')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARBMM3/B0eYYtwjFYdkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125ffaf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(average_rewards.shape[0]), average_rewards)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12511a990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = run_episode(agent, env, env.spec.max_episode_steps, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2 , -0.07])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.low.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6 ,  0.07])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
